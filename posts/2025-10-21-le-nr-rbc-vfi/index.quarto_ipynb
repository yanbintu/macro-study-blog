{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Low-Efficiency and Non-Robust RBC VFI\"\n",
        "author: \"Tu\"\n",
        "date: \"2025-10-21\"\n",
        "categories: [macro, code, replication]\n",
        "execute:\n",
        "  enabled: true\n",
        "  cache: true\n",
        "---\n",
        "\n",
        "这是一份低效率的、非稳健的使用值函数迭代求解标准 RBC 模型的非 python 风格的 python 代码。\n",
        "\n",
        "我们考虑的是下面的 social planner problem：\n",
        "$$\n",
        "\\begin{align*}\n",
        "    &\\mathbb{E}_0 \\sum_{t=0}^{\\infty} \\beta^t \\left[ \\frac{(C_t^\\nu (1-L_t)^{1-\\nu})^{1-\\gamma}}{1-\\gamma} \\right] \\\\[1ex]\n",
        "    \\text{s.t.} \\quad &C_t + K_{t+1} = e^{Z_t} K_t^\\alpha L_t^{1-\\alpha} + (1-\\delta)K_t \\\\\n",
        "    &Z_t = \\lambda Z_{t-1} + \\epsilon_t\\\\\n",
        "    &K_0,\\ Z_0 \\ \\text{are given}\n",
        "\\end{align*}\n",
        "$$ {#eq-01}\n",
        "\n",
        "Bellman equation:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "V(K_t, Z_t) = \\max_{C_t, L_t} \\left\\{ \\frac{(C_t^\\nu (1-L_t)^{1-\\nu})^{1-\\gamma}}{1-\\gamma} + \\beta \\mathbb{E}_t V(e^{Z_t} K_t^\\alpha L_t^{1-\\alpha} + (1-\\delta)K_t - C_t, Z_{t+1}) \\right\\}\n",
        "\\end{align*}\n",
        "$$ {#eq-02}\n",
        "\n",
        "接下来我们使用值函数迭代的方法来求解 $V(K, Z)$："
      ],
      "id": "83b2e9d2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "\n",
        "# %%\n",
        "import numpy as np\n",
        "import types\n",
        "from quantecon.markov import tauchen\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.optimize import minimize\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# %%\n",
        "#----------------------------------------------------------------\n",
        "# 1. Calibration: Parameters and Steady States\n",
        "#----------------------------------------------------------------\n",
        "P = types.SimpleNamespace() # Parameters\n",
        "SS = types.SimpleNamespace() # Steady states\n",
        "G = types.SimpleNamespace()  # Grids\n",
        "\n",
        "# Technology\n",
        "P.aalpha = 0.3\n",
        "P.bbeta  = 0.991\n",
        "P.ddelta = 0.0196\n",
        "\n",
        "# Preference parameters\n",
        "P.ggamma = 5\n",
        "\n",
        "# Productivity shocks\n",
        "P.llambda = 0.95\n",
        "P.ssigma  = 0.007\n",
        "\n",
        "# Compute Steady State values\n",
        "SS.lss = 1/3\n",
        "SS.kss = ((1-P.bbeta*(1-P.ddelta))/(P.aalpha*P.bbeta))**(1/(P.aalpha-1)) * SS.lss\n",
        "SS.css = (SS.kss**P.aalpha)*(SS.lss**(1-P.aalpha)) - P.ddelta*SS.kss\n",
        "P.nnu  = SS.css/((1-P.aalpha)*SS.kss**P.aalpha*SS.lss**(-P.aalpha)*(1-SS.lss)+SS.css)\n",
        "SS.vss = ((SS.css**P.nnu*(1-SS.lss)**(1-P.nnu))**(1-P.ggamma))/(1-P.ggamma)/(1-P.bbeta)\n",
        "\n",
        "# %%\n",
        "#----------------------------------------------------------------\n",
        "# 1a. Define utility function and production function\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "def u(c, l):\n",
        "\n",
        "    return ((c**P.nnu)*(1-l)**(1-P.nnu))**(1-P.ggamma)/(1-P.ggamma)\n",
        "\n",
        "def f(k, l, z):\n",
        "\n",
        "    return np.exp(z) * (k**P.aalpha) * (l**(1-P.aalpha))\n",
        "\n",
        "# %%\n",
        "#----------------------------------------------------------------\n",
        "# 2. Declare size vectors for grids\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "# Define boundaries for capital\n",
        "# consider the state space of 90% to 190% capital\n",
        "pRange_k_grid = 0.9;        \n",
        "G.k_min = (1-pRange_k_grid)*SS.kss\n",
        "G.k_max = (1+pRange_k_grid)*SS.kss\n",
        "G.k_pts = 41\n",
        "\n",
        "G.k_grid  = np.linspace(G.k_min,G.k_max,G.k_pts)\n",
        "G.k_dim = len(G.k_grid)\n",
        "\n",
        "# Productivity\n",
        "G.z_dim = 5    # number of nodes for technology process Z\n",
        "\n",
        "# %%\n",
        "#----------------------------------------------------------------\n",
        "# 3. Tauchen \n",
        "#----------------------------------------------------------------\n",
        "\n",
        "# find grid points and transition matrix using Tauchen's method\n",
        "mc = tauchen(G.z_dim, P.llambda, P.ssigma, mu=0)\n",
        "G.Z = mc.state_values\n",
        "G.PI = mc.P\n",
        "\n",
        "# size of state grids (the structure of solutions)\n",
        "G.s_grid = np.ones((G.k_dim, G.z_dim))\n",
        "\n",
        "# initialize guess solution for value function\n",
        "v_guess = np.ones_like(G.s_grid)\n",
        "\n",
        "# storage for value function and policy function\n",
        "maxIteration = 2000\n",
        "v_history = np.zeros((maxIteration, G.k_dim, G.z_dim))\n",
        "c_policy_history = np.zeros((maxIteration, G.k_dim, G.z_dim))\n",
        "l_policy_history = np.zeros((maxIteration, G.k_dim, G.z_dim))\n",
        "\n",
        "# %%\n",
        "#----------------------------------------------------------------\n",
        "# 3a. Define functions for value function iteration\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "# expected value function of k_prime\n",
        "def create_expected_value_interpolator(z_index, v_old):\n",
        "    \"\"\"\n",
        "    This is a factory function.\n",
        "    Its job is to create and return a callable function that computes the expected value.\n",
        "\n",
        "    Parameters:\n",
        "    z_index (int): The index of the current technology state z.\n",
        "    v_old (np.ndarray): The complete (k_dim, z_dim) value function array.\n",
        "    G: An object containing grids and the transition matrix.\n",
        "\n",
        "    Returns:\n",
        "    callable: A function that takes only k_prime as an argument.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. One-time setup: create 5 one-dimensional interpolation function objects.\n",
        "    #    We store these 5 functions in a list.\n",
        "    interpolators = []\n",
        "    for j in range(G.z_dim):\n",
        "        v_k_given_z_j = v_old[:, j]\n",
        "        # Create and store the callable interp1d function object\n",
        "        f_interp = interp1d(G.k_grid, v_k_given_z_j,\n",
        "                              kind='cubic',\n",
        "                              bounds_error = False,\n",
        "                              fill_value= \"extrapolate\") \n",
        "        interpolators.append(f_interp)\n",
        "\n",
        "    # 2. Get the one-time transition probabilities\n",
        "    transition_probs = G.PI[z_index, :]\n",
        "\n",
        "    # 3. Define and return the inner function (this is the callable object we need)\n",
        "    def expected_value_func(k_prime):\n",
        "        \"\"\"\n",
        "        This function calculates E[V(k', z') | z].\n",
        "        It can access 'interpolators' and 'transition_probs' defined in its outer scope.\n",
        "        This is a \"closure\".\n",
        "        \"\"\"\n",
        "        future_values = np.array([interp(k_prime) for interp in interpolators])\n",
        "        return np.dot(transition_probs, future_values)\n",
        "\n",
        "    # The factory function returns this inner function\n",
        "    return expected_value_func\n",
        "\n",
        "# right hand side of Bellman equation\n",
        "def bellman_rhs_for_optimizer(controls, states, expected_value_func):\n",
        "\n",
        "    c, l = controls\n",
        "    k, z = states\n",
        "    k_prime = f(k, l, z) + (1 - P.ddelta) * k - c\n",
        "    return u(c, l) + P.bbeta * expected_value_func(k_prime)\n",
        "\n",
        "# Bellman operator\n",
        "def T(v_old):\n",
        "\n",
        "    v_new = np.zeros_like(v_old)\n",
        "    c_policy = np.zeros_like(v_old)\n",
        "    l_policy = np.zeros_like(v_old)\n",
        "\n",
        "    expected_value_funcs = []\n",
        "    for j in range(G.z_dim):\n",
        "        expected_value_funcs.append(create_expected_value_interpolator(j, v_old))\n",
        "\n",
        "    for k_index, k_val in enumerate(G.k_grid):\n",
        "        for z_index, z_val in enumerate(G.Z):\n",
        "\n",
        "            states = (k_val, z_val)\n",
        "\n",
        "            # Bounds: C > 0, 0 <= L <= 1\n",
        "            bounds = [(1e-10, None), (1e-10, 1.0 - 1e-10)]\n",
        "\n",
        "            # Inequality Constraint: C <= f(k,l,z) + (1-δ)k\n",
        "            def inequality_constraint(controls, k, z):\n",
        "                c, l = controls\n",
        "                resources = f(k, l, z) + (1 - P.ddelta) * k\n",
        "                return resources - c\n",
        "\n",
        "            # Package the constraint into the dictionary format required by scipy\n",
        "            constraints = [{\n",
        "                'type': 'ineq',  # 'ineq' stands for an inequality constraint (>= 0)\n",
        "                'fun': inequality_constraint,\n",
        "                'args': (k_val, z_val) # Pass the current states k, z as extra arguments\n",
        "            }]\n",
        "\n",
        "           # Use a safe, guaranteed feasible guess\n",
        "            available_resources = f(k_val, SS.lss, z_val) + (1 - P.ddelta) * k_val\n",
        "            c_guess = 0.5 * available_resources\n",
        "            l_guess = SS.lss\n",
        "            initial_guess = [c_guess, l_guess]\n",
        "\n",
        "            # Define the optimization objective function\n",
        "            objective_func = lambda controls: -bellman_rhs_for_optimizer(controls, states, expected_value_funcs[z_index])\n",
        "\n",
        "            # Call the minimize function\n",
        "            result = minimize(\n",
        "                fun=objective_func,\n",
        "                x0=initial_guess,\n",
        "                args=(),  # objective_func is a lambda closure, no extra args needed\n",
        "                method='SLSQP',\n",
        "                bounds=bounds,\n",
        "                constraints=constraints\n",
        "            )\n",
        "\n",
        "            # Save the results\n",
        "            if result.success:\n",
        "                v_new[k_index, z_index] = -result.fun\n",
        "                c_policy[k_index, z_index] = result.x[0]\n",
        "                l_policy[k_index, z_index] = result.x[1]\n",
        "            else:\n",
        "                # If optimization fails, we can set a flag value and print a warning\n",
        "                v_new[k_index, z_index] = -1e10 # or other penalty value\n",
        "                print(f\"Warning: Optimization failed at (k={k_val:.2f}, z={z_val:.2f}): {result.message}\")\n",
        "\n",
        "    return v_new, c_policy, l_policy\n",
        "\n",
        "# %%\n",
        "#----------------------------------------------------------------\n",
        "# 4. Iteration\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "tol = 1e-4\n",
        "error = tol + 1\n",
        "v_old = v_guess\n",
        "\n",
        "i = 0\n",
        "while error > tol and i < maxIteration:\n",
        "\n",
        "    v_new, c_policy, l_policy = T(v_old)\n",
        "    error = np.max(np.abs(v_new - v_old))\n",
        "\n",
        "    v_history[i] = v_new\n",
        "    c_policy_history[i] = c_policy\n",
        "    l_policy_history[i] = l_policy\n",
        "\n",
        "    i = i + 1\n",
        "    v_old = v_new\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Error at iteration {i} is {error}.\")\n",
        "\n",
        "if error > tol:\n",
        "    print(\"Failed to converge!\")\n",
        "else:\n",
        "    print(f\"\\nConverged in {i} iterations.\")"
      ],
      "id": "2a505939",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Value function 迭代可视化："
      ],
      "id": "77761bd7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %%\n",
        "# value function\n",
        "\n",
        "z_steady_state_index = 2\n",
        "start = 0   # 任意整数起点\n",
        "step = 2  # 步长\n",
        "count = 50  # 前进次数\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "ax.plot(G.k_grid, v_history[0, :, z_steady_state_index], color=plt.cm.jet(0), label='First iteration')\n",
        "for j in range(start, start + step * count, step):\n",
        "\n",
        "    v_function_slice = v_history[j, :, z_steady_state_index]\n",
        "\n",
        "    ax.plot(G.k_grid, v_function_slice, color=plt.cm.jet((j-start)/(step*count)))\n",
        "\n",
        "ax.set_title(fr'Value function history (z = {G.Z[z_steady_state_index]:.2f})')\n",
        "ax.set_xlabel('K')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "id": "68a28911",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "消费的 policy function 迭代可视化："
      ],
      "id": "f102ac21"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %%\n",
        "# policy function for consumption\n",
        "\n",
        "z_steady_state_index = 2\n",
        "start = 10   # 任意整数起点\n",
        "step = 1  # 步长\n",
        "count = 50  # 前进次数\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "for j in range(start, start + step * count, step):\n",
        "\n",
        "    c_function_slice = c_policy_history[j, :, z_steady_state_index]\n",
        "\n",
        "    ax.plot(G.k_grid, c_function_slice, color=plt.cm.jet((j-start)/(step*count)))\n",
        "\n",
        "ax.set_title(fr'Policy function of C (z = {G.Z[z_steady_state_index]:.2f})')\n",
        "ax.set_xlabel('K')\n",
        "plt.show()"
      ],
      "id": "f4bded4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "劳动的 policy function 迭代可视化："
      ],
      "id": "dbca38d6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %%\n",
        "# policy function for labor\n",
        "\n",
        "z_steady_state_index = 2\n",
        "start = 10   # 任意整数起点\n",
        "step = 1  # 步长\n",
        "count = 50  # 前进次数\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "for j in range(start, start + step * count, step):\n",
        "\n",
        "    l_function_slice = l_policy_history[j, :, z_steady_state_index]\n",
        "\n",
        "    ax.plot(G.k_grid, l_function_slice, color=plt.cm.jet((j-start)/(step*count)))\n",
        "\n",
        "ax.set_title(fr'Policy function of L (z = {G.Z[z_steady_state_index]:.2f})')\n",
        "ax.set_xlabel('K')\n",
        "plt.show()"
      ],
      "id": "95dcf097",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最终的消费的解："
      ],
      "id": "318a56e0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %%\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "for j in range(0, G.z_dim):\n",
        "\n",
        "    c_function_slice = c_policy_history[i-1, :, j]\n",
        "    ax.plot(G.k_grid, c_function_slice, label=fr'z={G.Z[j]:.2f}')\n",
        "\n",
        "ax.set_title('Policy function of C after convergence(tol=1e-4)')\n",
        "ax.set_xlabel('K')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "id": "70be6c06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最终的劳动的解："
      ],
      "id": "b67e9b25"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %%\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "for j in range(0, G.z_dim):\n",
        "\n",
        "    l_function_slice = l_policy_history[i-1, :, j]\n",
        "    ax.plot(G.k_grid, l_function_slice, label=fr'z={G.Z[j]:.2f}')\n",
        "\n",
        "ax.set_title('Policy function of L after convergence(tol=1e-4)')\n",
        "ax.set_xlabel('K')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "id": "c0984c16",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\TYB\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}